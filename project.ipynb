{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan predictions\n",
    "\n",
    "We are going to review the project from the original learning lab, Automation of the loan eligibility process. It consists of original instructions and provided solutions. Run the code in your Jupyter and remember what we are doing in each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "We want to automate the loan eligibility process based on customer details that are provided as online application forms are being filled. You can find the dataset [here](https://drive.google.com/file/d/1h_jl9xqqqHflI5PsuiQd_soNYxzFfjKw/view?usp=sharing). These details concern the customer's Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and other things as well. \n",
    "\n",
    "|Variable| Description|\n",
    "|: ------------- |:-------------|\n",
    "|Loan_ID| Unique Loan ID|\n",
    "|Gender| Male/ Female|\n",
    "|Married| Applicant married (Y/N)|\n",
    "|Dependents| Number of dependents|\n",
    "|Education| Applicant Education (Graduate/ Under Graduate)|\n",
    "|Self_Employed| Self employed (Y/N)|\n",
    "|ApplicantIncome| Applicant income|\n",
    "|CoapplicantIncome| Coapplicant income|\n",
    "|LoanAmount| Loan amount in thousands|\n",
    "|Loan_Amount_Term| Term of loan in months|\n",
    "|Credit_History| credit history meets guidelines|\n",
    "|Property_Area| Urban/ Semi Urban/ Rural|\n",
    "|Loan_Status| Loan approved (Y/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. Making Predictions Using Pipeline\n",
    "Transform the original data prep, feat. engineering and modeling steps into Pipeline.\n",
    "\n",
    "The goal here is to create Pipeline that will take original rows from our dataset and predict the probability of being granted a loan for each row. No prior transformations should be applied to data before using Pipeline. The pipeline should have following steps:\n",
    "\n",
    "- Preprocessing pipeline\n",
    "    - **DataframeFunctionTransformer** - createing total_income\n",
    "    - **fill NA transformer** - we should use ColumnTransformer to fill NANs to different columns using different methods. \n",
    "    - **DataframeFunctionTransformer** - transforming back to DataFrame\n",
    "    - **log transformer** - we should use ColumnTransformer apply log transformation to LoanAmount and total_income (we will create total_income using DataframeFunctionTransformer)\n",
    "- OneHotEncoder\n",
    "- MinMaxScaler\n",
    "- RandomForest\n",
    "\n",
    "Use **GridSearch** to tune the parameters of RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:12:20.299091Z",
     "start_time": "2020-09-02T14:12:20.281477Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"data.csv\") \n",
    "df['Loan_Status'] = df['Loan_Status'].replace({'Y':1, 'N':0})\n",
    "\n",
    "# create X,y\n",
    "y = df.pop('Loan_Status')\n",
    "X = df.drop('Loan_ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:13:00.911756Z",
     "start_time": "2020-09-02T14:13:00.907544Z"
    }
   },
   "outputs": [],
   "source": [
    "# import additional libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:13:36.847247Z",
     "start_time": "2020-09-02T14:13:36.835722Z"
    }
   },
   "outputs": [],
   "source": [
    "# own data-frame transformer class we will use in pipeline\n",
    "class DataframeFunctionTransformer:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "def create_total_income_feature(input_df):\n",
    "    input_df['total_income'] = input_df['ApplicantIncome'] + input_df['CoapplicantIncome']\n",
    "    return input_df\n",
    "\n",
    "def to_dataframe(array):\n",
    "    columns= ['Gender','Dependents','Married','Self_Employed','LoanAmount',\n",
    "               'Loan_Amount_Term','Credit_History','Education','ApplicantIncome',\n",
    "               'CoapplicantIncome','Property_Area','total_income']\n",
    "    \n",
    "    return pd.DataFrame(array, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continue with your Pipeline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Persist your GridSearch Object using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy your model to cloud and test it with PostMan, BASH or Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:16:28.812012Z",
     "start_time": "2020-09-02T14:16:28.805283Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\"Gender\":\"Male\",\n",
    "        \"Married\":\"No\",\n",
    "        \"Dependents\":\"0\",\n",
    "        \"Education\":\"Graduate\",\n",
    "        \"Self_Employed\":\"No\",\n",
    "        \"ApplicantIncome\":5849,\n",
    "        \"CoapplicantIncome\":0.0,\n",
    "        \"LoanAmount\": None,\n",
    "        \"Loan_Amount_Term\":360.0,\n",
    "        \"Credit_History\":1.0,\n",
    "        \"Property_Area\":\"Urban\",\n",
    "        \"total_income\":5849.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:16:30.974956Z",
     "start_time": "2020-09-02T14:16:30.641744Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "URL = \"http:<your AWS instance>:5000/<your endpoint>\"\n",
    "\n",
    "# sending get request and saving the response as response object \n",
    "r = requests.post(url = URL, json = data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:16:32.312748Z",
     "start_time": "2020-09-02T14:16:32.305870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.075, 0.925]]\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
